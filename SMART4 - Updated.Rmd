---
title: "Smart4 - Updated"
author: "Andrea Piolini"
date: "11/24/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(include = F)
knitr::opts_chunk$set(collapse = T, results = 'hide', warning = F, message = F, error = F)
options(scientific=T, digits = 3)
options(scipen=999)
```

```{r basicfcn}
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r setting_wd}
setwd('C:/Users/andre/Desktop/GW Classes/Introduction to Data Science')
```

```{r init}
loadPkg('readxl')
#loading the datasets
gdp <- read_excel("GDP_Super_Cool.xlsm")
athlete_events <- data.frame(read.csv("athlete_events.csv"))
NOC <- data.frame(read.csv("noc_regions.csv"))
```

```{r cleaning_data}
# keeping NAs for analysis of winners and losers
summer_w_NAs = athlete_events[athlete_events$Season=='Summer',]

# differenciate between winners and losers
# THIS IS VERY IMPORTANT PART OF THE CODE
summer_w_NAs <- subset(athlete_events, Season == 'Summer')
summer_w_NAs$Medal <- as.character(summer_w_NAs$Medal)
summer_w_NAs$Medal[is.na(summer_w_NAs$Medal)] <- "Loser"
summer_w_NAs$Medal[summer_w_NAs$Medal == 'Bronze'] <- 'Winner'
summer_w_NAs$Medal[summer_w_NAs$Medal == 'Silver'] <- 'Winner'
summer_w_NAs$Medal[summer_w_NAs$Medal == 'Gold'] <- 'Winner'
```

```{r merging_dataframe_with_NOC}
#merging the NOc dataset with Summer_w_NAs by NOC
SummerNOC = merge(summer_w_NAs, NOC, by=c("NOC"))
str(SummerNOC)
```

```{r missing_values}
#identifying the missing values for the region column
sum(is.na(SummerNOC$region))
regionNA <- SummerNOC[is.na(SummerNOC$region),]
regionNA
```

```{r deleting_NAs}
#decided to delete the NAs in the region column as they are not relevant for the analysis
SummerNOC <- SummerNOC[!is.na(SummerNOC$region), ]
SummerNOC <- SummerNOC[ , -8]
SummerNOC <- SummerNOC[ , -16]
#renaming the region column to Country
colnames(SummerNOC)[which(names(SummerNOC) == "region")] <- "Country"
```

```{r renaming_countries}
#renaming some of the countries in the gdp dataset as they have a different name in the SummerNOC dataset. This will allow us to create a more accurate dataframe when we merge gdp and SummerNOC
gdp$Country[gdp$Country == 'Egypt, Arab Rep.'] <- 'Egypt'
gdp$Country[gdp$Country == 'Bahamas, The'] <- 'Bahamas'
gdp$Country[gdp$Country == 'Iran, Islamic Rep.'] <- 'Iran'
gdp$Country[gdp$Country == "Cote d'Ivoire"] <- 'Ivory Coast'
gdp$Country[gdp$Country == 'Kyrgyz Republic'] <- 'Kyrgyzstan'
gdp$Country[gdp$Country == 'North Macedonia'] <- 'Macedonia'
gdp$Country[gdp$Country == "Korea, Dem. People's Rep."] <- 'North Korea'
gdp$Country[gdp$Country == 'Russian Federation'] <- 'Russia'
gdp$Country[gdp$Country == 'Slovak Republic'] <- 'Slovakia'
gdp$Country[gdp$Country == 'Korea, Rep.'] <- 'South Korea'
gdp$Country[gdp$Country == 'Syrian Arab Republic'] <- 'Syria'
gdp$Country[gdp$Country == 'Trinidad and Tobago'] <- 'Trinidad'
gdp$Country[gdp$Country == 'United Kingdom'] <- 'UK'
gdp$Country[gdp$Country == 'United States'] <- 'USA'
gdp$Country[gdp$Country == 'Venezuela, RB'] <- 'Venezuela'
gdp$Country[gdp$Country == 'Virgin Islands (U.S.)'] <- 'Virgin Islands, US'
```

```{r new_dataset}
#creating a new data frame SummerGDP by merging SummerNOC and gdp by Year and Country
Summer_GDP = merge(SummerNOC, gdp, by=c("Country", "Year"))
str(Summer_GDP)
```

```{r new_dataset_1}
#scaling GDP, converting Medal to factor, and removing NAs
Summer_GDP$GDP <- scale(Summer_GDP$GDP)
Summer_GDP$Medal <- as.factor(Summer_GDP$Medal)
sum(is.na(Summer_GDP))
Summer_GDP_nona <- na.omit(Summer_GDP)
```

```{r new_dataset_2}
#displaying the number of rows of the new data frame withou NA
nrow(Summer_GDP_nona)
```

```{r graph1}
#creating a bix plot that displays Winner/Losers and GDP
plot(GDP ~ Medal, data = Summer_GDP_nona, main = "GDP for Losers and Winners", xlab = "Loser/Winner", ylab = "GDP", col = c("darkblue", "antiquewhite"))
```

```{r Anova1}
#Performing ANOVA test on GDP and Medal
GDP_aov <- aov(GDP ~ Medal, data = Summer_GDP_nona)
names(GDP_aov)
summary(GDP_aov)
```

The null hypothesis of this test is the following: the people who won a medal and people who did not win a medal have the same mean for GDP. 

From the ANOVA test we got a really tiny p-value which is way smaller than our confidence level 0.05 and therefore we reject the null hypothesis and conclude that GDP has an effect on whether an athlete earns a medal. As we can see visually from the boxplot, athletes who won a medal tend to come from countries with higher GDP.  


```{r logistic_regression}
#performing Logistic regression on GDP and Medal
GDPLogit <- glm(Medal ~ GDP, data = Summer_GDP_nona, family = "binomial")
summary(GDPLogit)
```

To evaluate whether our model is good, we are going to perform the following tests: 

* Receiver-Operator-Characteristic curve and Area-Under-Curve:
```{r ROC, include = TRUE, echo= FALSE}
loadPkg("pROC")
prob = predict(GDPLogit, type = c("response"))
Summer_GDP_nona$prob=prob
g <- roc(Medal~prob, data= Summer_GDP_nona)
auc(g)
plot(g)
#roc_obj <- roc(data2$Medal, data2$GDP)
##auc(roc_obj)
#plot(roc_obj)
```

The area-under-curve for this model is `r auc(g)`, which is less than 0.8. Althought `r auc(g)` is not much smaller than 0.8, this means that this model is not a good fit.

* McFadden:

```{r McFadden}
loadPkg("pscl")
GDPLogitpr2 = pR2(GDPLogit)
GDPLogitpr2
```

With the McFadden value of `r format(GDPLogit['McFadden'], 4)` only 2% of the variation in y is explained by the explanatory variables in the model, which is not good.

```{r logistic_regression2}
#running logistic regression with more variables to see whether it improves the model
GDPLogit1 <- glm(Medal ~ GDP+Height+Weight+ Age, data = Summer_GDP_nona, family = "binomial")
summary(GDPLogit1)
```

To evaluate whether our model is good, we are going to perform the following tests: 

* Receiver-Operator-Characteristic curve and Area-Under-Curve:
```{r ROC1, include = TRUE, echo= FALSE}
prob1 = predict(GDPLogit1, type = c("response"))
Summer_GDP_nona$prob1=prob1
h <- roc(Medal~prob1, data= Summer_GDP_nona)
auc(h)
plot(h)
```

The area-under-curve for this model is `r auc(h)`, which is less than 0.8. Althought `r auc(h)` is not much smaller than 0.8, this means that this model is not a good fit.

* McFadden:

```{r McFadden1}
loadPkg("pscl")
GDPLogitpr2_1 = pR2(GDPLogit1)
GDPLogitpr2_1
```

In this case, we got a McFadden value of `r format(GDPLogit1['McFadden'], 4)`. This means that our model is a good fit. 

* We are aslo going to run the Aikake information criterion to compare the two models and see which one of the two is better. 

```{r Q8c}
AIC(GDPLogit)
AIC(GDPLogit1)
```

We got `r AIC(GDPLogit)` for the first model and `r AIC(GDPLogit1)` for the second model.That means that the second model is better as its value is lower. 

```{r graph2}
#plotting GDP and Sex in a boxplot
plot(GDP ~ Sex, data = Summer_GDP_nona, main = "GDP for Men and Women", xlab = "Men/Women", ylab = "GDP", col = c("deeppink1", "dodgerblue1"))
```

```{r ANOVA2}
#running ANOVA test for GDP and Sex
GDP_Sex_aov <- aov(GDP ~ Sex, data = Summer_GDP_nona)
names(GDP_Sex_aov)
summary(GDP_Sex_aov)
```

The null hypothesis of this test is the following: the female athletes and male athletes have the same mean for GDP. 

From the ANOVA test we got a really tiny p-value which is way smaller than our confidence level 0.05 and therefore we reject the null hypothesis and conclude that GDP has an effect on whether female athletes partecipate to the olympics. As we can see visually from the boxplot, female athletes tend to partecipate more often if they come from a country with a higher GDP. 

```{r frequency_table}
#creating a frequency table with the number of participants for each country over the years
table1 <- table(Summer_GDP_nona$Country, Summer_GDP_nona$Year)
table1 <- data.frame(table1) #converting the table into a data frame
#renaming the columns in table1. The Freq column actually indicates the number of participants for each country each year and therefore it was named Participants
colnames(table1)[which(names(table1) == "Var1")] <- "Country"
colnames(table1)[which(names(table1) == "Var2")] <- "Year"
colnames(table1)[which(names(table1) == "Freq")] <- "Participants"
```

```{r another_new_dataframe}
#merging table1 and gdp to create a new data frame SummerGDPFreq 
SummerGDPFreq = merge(table1, gdp, by=c("Country", "Year"))
sum(is.na(SummerGDPFreq$GDP))
SummerGDPFreq <- SummerGDPFreq[!is.na(SummerGDPFreq$GDP), ]
SummerGDPFreq$GDP <- scale(SummerGDPFreq$GDP)
str(SummerGDPFreq)
```

```{r correlation_table}
GDPFreqcor <- cor(SummerGDPFreq[3:4])
GDPFreqcor
```

```{r corrplot}
loadPkg("corrplot")
corrplot(GDPFreqcor)
corrplot(GDPFreqcor, method = "number")
```

```{r lm1}
model1 <- lm(Participants ~ GDP, data = SummerGDPFreq)
summary(model1)
slope <- coef(model1)
slope
```

After we ran our linear regression model, we got an intercept of `r format(coef(model1)[1])` and a slope of `r format(coef(model1)[2])`. This means that for an increase of one point for the scaled GDP, which is worth billions of dollars, we expect an increase of more than 72 participants in total on average. Additionally, we got a really tiny p-value for the slope. Therefore, we reject the null hypotheisis, which is that the intercept and the slope is equal to 0, and we say that our slope is statistically significant. 

Finally, we got an R-squared value of 0.336. This means that our model accounts for approximately 34% of the variance.

```{r lm1_plotted}
plot(model1)
loadPkg("ggplot2")
ggplot(model1,aes(GDP,Participants))+geom_point(aes(GDP,Participants)) + geom_line(aes(Participants), colour="red", size=1)
```

```{r starting_KNN}
loadPkg("FNN")
head(summer_w_NAs)
#first we want to scale the data so KNN will operate correctly
scaledoly1 <- as.data.frame(scale(Summer_GDP_nona[c(7:9, 16)], center = TRUE, scale = TRUE))
```
 
```{r setting_sample}
set.seed(1)
oly_sample1 <- sample(2, nrow(scaledoly1), replace=TRUE, prob=c(0.67, 0.33))
oly_sample1
scaledoly1
```

```{r creating_training_and_test}
oly_training1 <- scaledoly1[oly_sample1==1, 1:3]
oly_test1 <- scaledoly1[oly_sample1==2, 1:3]
```

```{r creating_YValues}
#Now we need to create our 'Y' variables or labels need to input into the KNN function
oly.trainLabels1 <- Summer_GDP_nona[oly_sample1==1, 15]
oly.testLabels1 <- Summer_GDP_nona[oly_sample1==2, 15]
```

```{r K3}
#So now we will deploy our model 
oly_pred1 <- knn(train = oly_training1, test = oly_test1, cl=oly.trainLabels1, k=3)
oly_pred1
```

```{r K3_crosstable, include= TRUE, echo = False}
loadPkg("gmodels")
OLYPREDCross1 <- CrossTable(oly.testLabels1, oly_pred1, prop.chisq = FALSE)
#Looks like we got all but three correct, not bad
```

```{r K5}
#So now we will deploy our model 
oly_pred2 <- knn(train = oly_training1, test = oly_test1, cl=oly.trainLabels1, k=5)
oly_pred2
```

```{r K5_crosstable}
#install.packages("gmodels")
loadPkg("gmodels")
OLYPREDCross2 <- CrossTable(oly.testLabels1, oly_pred2, prop.chisq = FALSE)
#Looks like we got all but three correct, not bad
```

```{r K7}
#So now we will deploy our model 
oly_pred3 <- knn(train = oly_training1, test = oly_test1, cl=oly.trainLabels1, k=7)
oly_pred3
```

```{r K7_crosstable}
OLYPREDCross3 <- CrossTable(oly.testLabels1, oly_pred3, prop.chisq = FALSE)
#Looks like we got all but three correct, not bad
```

```{r acc1}
kNN_acc1 =  100 * sum(oly.testLabels1 == oly_pred1)/NROW(oly.testLabels1)
kNN_acc1
```

```{r acc2}
kNN_acc2 =  100 * sum(oly.testLabels1 == oly_pred2)/NROW(oly.testLabels1)
kNN_acc2
```

```{r acc3}
kNN_acc3 =  100 * sum(oly.testLabels1 == oly_pred3)/NROW(oly.testLabels1)
kNN_acc3
```
